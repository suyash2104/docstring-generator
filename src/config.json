{
    "modelPath": "../models/",
    "modelName": "tinyllama-1.1b-chat-v1.0.Q5_0.gguf",
    "gpuLayers": 0,
    "contextSize": 1024,
    "maxTokens": 300,
    "temperature": 0.05,
    "topP": 0.8,
    "stopSequences": ["\"\"\"", "</s>", "Function:"],
    "repeatPenalty": 1.1,
    "repo": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
    "filename": "tinyllama-1.1b-chat-v1.0.Q5_0.gguf"
}